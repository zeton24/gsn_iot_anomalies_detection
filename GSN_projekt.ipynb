{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WSU2a0sLxUeP",
        "xksGPv6tKcVf",
        "8XZXq2RN_8Fq",
        "lka_Av-N-0ZV",
        "VPwSvIEZ6dDF",
        "2ctLoR9A6iJg",
        "ogyerTgz_oHr",
        "yUGNwLMMytk3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeton24/gsn_iot_anomalies_detection/blob/main/GSN_projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional (Conv2d)\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
        "\n",
        "Average Pooling https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d\n",
        "\n",
        "Normalization\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d\n",
        "\n",
        "Spatial Dropout\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html#torch.nn.Dropout2d\n",
        "\n",
        "Fully connected layer -> nn.Linear()\n"
      ],
      "metadata": {
        "id": "f8AlM5uOovz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stara wersja"
      ],
      "metadata": {
        "id": "WSU2a0sLxUeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "YsotMKY_-viE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "cM7kc7THAPKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset i Dataloader"
      ],
      "metadata": {
        "id": "xksGPv6tKcVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "todo\n",
        " - transformy w datasecie\n",
        " - tensory na wyjściu dataloadera"
      ],
      "metadata": {
        "id": "GmT59WpvYdG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(category, n_classes):\n",
        "  result = torch.zeros(n_classes)\n",
        "  result[category] = 1\n",
        "  return result"
      ],
      "metadata": {
        "id": "YcYWDfJyAL0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wzięte z https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "# i znacząco zmienione, bo my mamy 1 plik wejściowy, a oni folder z obrazkami\n",
        "# jak to nie będzie mega powolne, to spoko, ale może być powolne i wtedy nie wiem, co robimy\n",
        "\n",
        "class IoTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, input_file):\n",
        "    self.input_file = open(input_file, \"r\")\n",
        "    self.dict_of_classes = {\"Mirai-Ackflooding\": 0, \"Mirai-Hostbruteforceg\": 1, \"Mirai-UDP Flooding\": 2, \"Mirai-HTTP Flooding\": 3,\n",
        "                            \"DoS-Synflooding\": 4, \"Scan Port OS\": 5, \"Normal\": 6} # todo reszta klas\n",
        "    self.n_classes = 16 # len(self.dict_of_classes)\n",
        "\n",
        "  def __len__(self):\n",
        "    i = 0\n",
        "    for i, line in enumerate(self.input_file):\n",
        "      pass\n",
        "    self.input_file.seek(0)\n",
        "    return 4 # i + 1\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    for i, line in enumerate(self.input_file):\n",
        "      if i == idx:\n",
        "        data = line.split(\";\") # docelowo zmienić na \",\"\n",
        "\n",
        "        image = torch.Tensor(list(map(float, data[:64])))\n",
        "        image = torch.reshape(image, (1,64))\n",
        "\n",
        "        label = data[-1]\n",
        "        if label.endswith(\"\\n\"):\n",
        "          label = label[:-1]\n",
        "        label = self.dict_of_classes[label] # -2, lub -3 dla prostszych przypadków\n",
        "        label = to_one_hot(label, self.n_classes)\n",
        "\n",
        "        self.input_file.seek(0)\n",
        "        break\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "jwh6V7mTKbTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = IoTDataset(\"test_dataset.csv\")\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "R1MIiyx0QK9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_features, train_labels in dataloader:\n",
        "  print(train_features.shape, train_features.dtype)\n",
        "  print(train_labels)\n",
        "  break"
      ],
      "metadata": {
        "id": "MfobgY3tXgeE",
        "outputId": "9d22aff0-333d-4b69-a2d1-101a7a4bc3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 64]) torch.float32\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elementy do wykorzystania"
      ],
      "metadata": {
        "id": "8XZXq2RN_8Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modele sieci 1D, 2D, 3D"
      ],
      "metadata": {
        "id": "lka_Av-N-0ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model1D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        # Nazwa bloku do rozważenia, taka mi się wymyśliła, ale nie upieram się przy niej.\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 16)\n",
        "            # Bez aktywacji na końcu, bo softmax się doda automatycznie razem z cross entropy.\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DMoPFNCg-5Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Oni w artykule dają normalizację, ale pytorch wywala błąd.\n",
        "            # Moim zdaniem słusznie, bo o ile rozumiem ten wzór na normalizację (co jest w dokumentacji),\n",
        "            # to przy wymiarze wejścia [batch_size, 256, 1, 1] wyjście to tensor zer o takim samym wymiarze.\n",
        "            # Po prostu normalizacja zmienia nam średnią na 0 (odchylenie standardowe też, ale to nieistotne),\n",
        "            # a jak mamy 1 element, to zmiana średniej na 0, to zmiana elementu na 0.\n",
        "            # Więc nawet jak jakoś obejdziemy ten błąd, to wyniki będą bez sensu.\n",
        "            # Moim zdaniem w artykule jest błąd (a przynajmniej na rysunku, może w implementacji tego nie ma).\n",
        "\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 16)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (x.shape[0],1,8,8)) # można ten reshape dać gdzie indziej jak się znajdzie lepsze miejsce\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BI-iPxXK-5M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwt-wXMAd5-L"
      },
      "outputs": [],
      "source": [
        "class Model3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.AvgPool3d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.AvgPool3d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(256),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 16)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (x.shape[0],1,4,4,4))\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch loader"
      ],
      "metadata": {
        "id": "VPwSvIEZ6dDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Na bazie datasetu z labów - zwraca kolejne batche.\n",
        "# Nie jest jakiś genialny, ale i tak go używam tylko tu do testów.\n",
        "\n",
        "class Dataset:\n",
        "  def __init__(self, data, labels, batch_size=1):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.n_batches = len(self.data) // batch_size\n",
        "\n",
        "  def __iter__(self):\n",
        "    for i in range(self.n_batches):\n",
        "      inputs = torch.zeros(self.batch_size, 1, 64) # shape zahardkodowany\n",
        "      labels = torch.zeros(self.batch_size, self.labels.shape[1])\n",
        "\n",
        "      for j in range(self.batch_size):\n",
        "        inputs[j, 0] = self.data[i*self.batch_size+j]\n",
        "        labels[j]= self.labels[i*self.batch_size+j]\n",
        "\n",
        "      yield inputs, labels\n",
        "\n",
        "  # todo - jakiś shuffle by się przydał, ale to tylko jeśli byśmy z tego korzystały"
      ],
      "metadata": {
        "id": "aSnHM9rz2uYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funkcje do treningu i testowania"
      ],
      "metadata": {
        "id": "2ctLoR9A6iJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja przeprowadzająca traning\n",
        "def train(net, loader, optimizer, criterion, epochs):\n",
        "  net.train()\n",
        "  for epoch in range(epochs):\n",
        "    epoch_loss = 0.\n",
        "    for i, (inputs, labels) in enumerate(loader):\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss\n",
        "\n",
        "    # Wczesne przerwanie w razie dostatecznie dobrych wyników.\n",
        "    if epoch_loss<0.05:\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] eloss: {epoch_loss:.3f}')\n",
        "      break\n",
        "\n",
        "    if epoch % 20 == 19: # wypisywanie co 20 epok\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] eloss: {epoch_loss:.3f}')"
      ],
      "metadata": {
        "id": "80aVYkDFK4oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(network, test_set, n_classes = 16):\n",
        "  network.eval() # Przełącza sieć w tryb testowania, m. in. wyłącza dropouta.\n",
        "  err_matrix = torch.zeros((n_classes, n_classes), dtype=int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for inputs, labels in test_set:\n",
        "\n",
        "      outputs = network(inputs)\n",
        "\n",
        "      _, label = torch.max(labels, 1)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "      for truth, prediction in zip(label, predicted):\n",
        "        err_matrix[truth, prediction] += 1\n",
        "\n",
        "  return err_matrix"
      ],
      "metadata": {
        "id": "HKHJHsinOxPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja tworzy losowe etykiety one-hot.\n",
        "\n",
        "def rand_and_predict(dataset_size, output_length):\n",
        "  labels = torch.zeros(dataset_size, output_length)\n",
        "  for i in range(dataset_size):\n",
        "    hot = torch.randint(output_length,(1,))\n",
        "    labels[i, hot] = 1\n",
        "  return labels\n"
      ],
      "metadata": {
        "id": "vp9UCrvpG6LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test na małych danych"
      ],
      "metadata": {
        "id": "ogyerTgz_oHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputsR = torch.rand(24,1,64)\n",
        "labelsR = rand_and_predict(24,16)"
      ],
      "metadata": {
        "id": "gs1Ignft8Yru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {\"Mirai-Ackflooding\": 0, \"Mirai-Hostbruteforceg\": 1, \"Mirai-UDP Flooding\": 2, \"Mirai-HTTP Flooding\": 3, \"DoS-Synflooding\": 4, \"Scan Port OS\": 5, \"Normal\": 6}\n",
        "inputs = torch.zeros(24,1,64)\n",
        "labels = torch.zeros(24,16)\n",
        "with open('test_dataset.csv') as f:\n",
        "  for i, line in enumerate(f):\n",
        "    data = line.split(\";\") # docelowo zmienić na \",\"\n",
        "    image = torch.Tensor(list(map(float, data[1:65])))\n",
        "    image = torch.reshape(image, (1,64))\n",
        "\n",
        "    label = data[-1]\n",
        "    if label.endswith(\"\\n\"):\n",
        "      label = label[:-1]\n",
        "    label = classes[label]\n",
        "    label = to_one_hot(label, 16)\n",
        "\n",
        "    inputs[i] = image\n",
        "    labels[i] = label"
      ],
      "metadata": {
        "id": "kvYZRLjhGL-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = Dataset(inputs, labels, batch_size=1)"
      ],
      "metadata": {
        "id": "IIyXs5qFrd8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_test = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "dcips5nY1GwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1D"
      ],
      "metadata": {
        "id": "skdjpL2v8Tue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network1 = Model1D()\n",
        "optimizer1 = optim.Adam(network1.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "aM2wHDnc86Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(network1, dataloader, optimizer1, criterion, 1000)"
      ],
      "metadata": {
        "id": "8zkn_Dco9CGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d042ef-0c4f-4145-d75b-1abc0649bfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20,     2] eloss: 0.773\n",
            "[40,     2] eloss: 0.464\n",
            "[60,     2] eloss: 0.220\n",
            "[65,     2] eloss: 0.046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = test(network1, dataloader)\n",
        "print(f\"Accuracy: {sum(sum(result1*torch.eye(16)))*100/sum(sum(result1)):.2f}%\")\n",
        "print(result1)"
      ],
      "metadata": {
        "id": "XgWnwhTb5McQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9945b0f-d5bc-4bb5-9f7a-01fe8331c29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2D"
      ],
      "metadata": {
        "id": "S8AgdBFHBHbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network2 = Model2D()\n",
        "optimizer2 = optim.Adam(network2.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "DLvlw3ilBHbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(network2, dataloader, optimizer2, criterion, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ed12fb-a7ca-4875-b36d-1b592f140b99",
        "id": "WI6na7CEBHbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20,     2] eloss: 3.156\n",
            "[40,     2] eloss: 3.729\n",
            "[60,     2] eloss: 2.365\n",
            "[80,     2] eloss: 1.382\n",
            "[100,     2] eloss: 0.487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = test(network2, dataloader)\n",
        "print(f\"Accuracy: {sum(sum(result2*torch.eye(16)))*100/sum(sum(result2)):.2f}%\")\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620de886-a9ae-4348-d33e-a2b9b6404331",
        "id": "xDRV00hzBHbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.00%\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3D"
      ],
      "metadata": {
        "id": "Z_P-0rNkFxnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network3 = Model3D()\n",
        "optimizer3 = optim.Adam(network3.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7-Mk5B2KFxnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(network3, dataloader, optimizer3, criterion, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92415661-accd-42cc-aa83-dbfc0399dbb8",
        "id": "3I0UN6PhFxnE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20,     2] eloss: 1.973\n",
            "[40,     2] eloss: 1.932\n",
            "[60,     2] eloss: 2.405\n",
            "[80,     2] eloss: 3.536\n",
            "[100,     2] eloss: 2.386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result3 = test(network3, dataloader)\n",
        "print(f\"Accuracy: {sum(sum(result3*torch.eye(16)))*100/sum(sum(result3)):.2f}%\")\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ad2c0c-bb1d-44ed-c0ed-ea0a311379c2",
        "id": "9oslUrSAFxnE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.00%\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lightning"
      ],
      "metadata": {
        "id": "l4pUUVvFxbN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dane"
      ],
      "metadata": {
        "id": "0LsCRRZTy15-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vWsChpYB0KWJ",
        "outputId": "290e7a54-e8f5-4895-ec30-a5ea4934f287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Collecting polars\n",
            "  Downloading polars-0.20.26-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "  Attempting uninstall: polars\n",
            "    Found existing installation: polars 0.20.2\n",
            "    Uninstalling polars-0.20.2:\n",
            "      Successfully uninstalled polars-0.20.2\n",
            "Successfully installed polars-0.20.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch-lightning"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Uv1-bhe_PWNI",
        "outputId": "41ca7a49-fb5a-458e-af74-12267dcfe7ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting pretty-errors==1.2.25 (from torchmetrics>=0.7.0->pytorch-lightning)\n",
            "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
            "Collecting colorama (from pretty-errors==1.2.25->torchmetrics>=0.7.0->pytorch-lightning)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "Successfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 pytorch-lightning-2.2.4 torchmetrics-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import polars\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "kTh52XTTypc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import PIL\n",
        "#import torch.nn as nn\n",
        "#import torch.nn.functional as F\n",
        "#import torchmetrics\n",
        "#from IPython.display import display\n",
        "#from pytorch_lightning import Trainer\n",
        "#from scipy.io import loadmat\n",
        "\n",
        "#from torchvision import models\n",
        "#from torchvision.datasets import ImageFolder\n",
        "#from torchvision.transforms import Resize, Compose, ToTensor, Normalize, ToPILImage\n",
        "#import hydra\n",
        "#from hydra.utils import instantiate"
      ],
      "metadata": {
        "id": "VLRNKnYlPVzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LazyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, inputs: torch.tensor, labels: torch.tensor, n_classes: int):\n",
        "    self.inputs = inputs\n",
        "    self.labels = labels\n",
        "    self.n_classes = n_classes\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    temp = torch.zeros(self.n_classes, dtype=torch.uint8)\n",
        "    temp[self.labels[idx].item()] = 1\n",
        "    return self.inputs[idx], temp"
      ],
      "metadata": {
        "id": "NDCFHXBeZeK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IoTDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, file_id: str, file_name: str, batch_size: int=64, binary_classification: bool=False):\n",
        "    super().__init__()\n",
        "    self.file_id = file_id\n",
        "    self.file_name = file_name\n",
        "    self.batch_size = batch_size\n",
        "    self.binary_classification = binary_classification\n",
        "\n",
        "    if self.binary_classification:\n",
        "      self.n_classes = 2\n",
        "      self.mapping = {\"Normal\": 0, \"Anomaly\": 1}\n",
        "    else:\n",
        "      self.n_classes = 5\n",
        "      self.mapping = {'Normal': 0, 'Mirai': 1, 'DoS': 2, 'Scan': 3, 'MITM ARP Spoofing': 4}\n",
        "\n",
        "  def prepare_data(self):\n",
        "    if not os.path.exists(self.file_name):\n",
        "      gdown.download(id=self.file_id, output=self.file_name)\n",
        "\n",
        "  def setup(self,stage = None):\n",
        "    data = torch.reshape(polars.read_csv(self.file_name, columns = range(64)).cast(polars.Float32).to_torch().to(torch.float16), (-1, 1, 64))\n",
        "\n",
        "    if self.binary_classification:\n",
        "      labels = torch.reshape(polars.read_csv(self.file_name, columns = [64])['Label'].replace(self.mapping, return_dtype=polars.UInt8).to_torch(), (-1, 1))\n",
        "    else:\n",
        "      #labels = torch.reshape(polars.read_csv(self.file_name, columns = [65])['Cat'].replace(self.mapping, return_dtype=polars.UInt8).to_torch(), (-1, 1))\n",
        "      labels = polars.read_csv(self.file_name, columns = [65])['Cat'].replace(self.mapping, return_dtype=polars.UInt8).to_torch()\n",
        "    dataset = LazyDataset(data, labels, self.n_classes)\n",
        "    del data, labels\n",
        "\n",
        "    # Train, test i val.\n",
        "    l = len(dataset)\n",
        "    train_and_val_size = int(l * .75)\n",
        "    dataset, self.test_dataset = random_split(dataset, [train_and_val_size, l - train_and_val_size])\n",
        "\n",
        "    train_size = int(train_and_val_size * .9)\n",
        "    self.train_dataset, self.val_dataset = random_split(dataset, [train_size, train_and_val_size - train_size])\n",
        "    del dataset\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ],
      "metadata": {
        "id": "0h7Dt7zeNvHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = IoTDataModule(file_id='1k8RqOM7hBvL8uomcKnnLr5HasYRWnYeW', file_name='iot-intrusion_with_headers.csv')"
      ],
      "metadata": {
        "id": "PVkbHeqvmnTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.prepare_data()\n",
        "dm.setup()"
      ],
      "metadata": {
        "id": "tUGwTG_FsB4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = len(dm.train_dataset)\n",
        "b = len(dm.val_dataset)\n",
        "c = len(dm.test_dataset)\n",
        "d=a+b+c"
      ],
      "metadata": {
        "id": "EZROdc9jyMwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(d)\n",
        "print(a/d*40/27)\n",
        "print(b/d*40/3)\n",
        "print(c/d*4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq0iKMofcBa7",
        "outputId": "4d03c7a9-ecd3-43a5-90f6-40be7d02910c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625783\n",
            "0.9999987571126449\n",
            "1.000005859326103\n",
            "1.0000015979980281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input, label in dm.test_dataloader():\n",
        "  print(input.shape)\n",
        "  print(label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KesQhlhPc5as",
        "outputId": "f4e1a41e-0cc6-41b2-84e6-cfe2fc3c6960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 64])\n",
            "tensor([[0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "yUGNwLMMytk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "YhvuqsjAxmL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### trening"
      ],
      "metadata": {
        "id": "gtPyceigyxaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dm.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3jv-2oY4S6w",
        "outputId": "86c3492f-daf8-449d-c1a1-15f8fe473412",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000e+00, 7.5000e+01, 1.0000e+00,  ..., 7.5000e+01,\n",
            "          0.0000e+00, 7.5000e+01]],\n",
            "\n",
            "        [[1.0000e+00, 5.3120e+03, 1.0000e+00,  ..., 2.6560e+03,\n",
            "          2.2620e+03, 4.2560e+03]],\n",
            "\n",
            "        [[2.0000e+00, 1.4100e+02, 0.0000e+00,  ..., 7.0500e+01,\n",
            "          7.0703e-01, 7.1000e+01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[2.1000e+01, 7.4000e+01, 1.0000e+00,  ..., 7.4000e+01,\n",
            "          0.0000e+00, 7.4000e+01]],\n",
            "\n",
            "        [[2.2000e+01, 1.2300e+02, 0.0000e+00,  ..., 1.2300e+02,\n",
            "          0.0000e+00, 1.2300e+02]],\n",
            "\n",
            "        [[2.3000e+01, 1.9900e+02, 1.0000e+00,  ..., 1.9900e+02,\n",
            "          0.0000e+00, 1.9900e+02]]], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dm = IoTDataModule()\n",
        "dm.setup()\n",
        "# label = to_one_hot(self.dict_of_classes[text_label], self.n_classes)\n",
        "dataloader_for_show = dm.train_dataloader()\n",
        "images_for_show = next(iter(dataloader_for_show))"
      ],
      "metadata": {
        "id": "hx_PB0ZMutKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trening"
      ],
      "metadata": {
        "id": "__RInNSMxn9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poligon"
      ],
      "metadata": {
        "id": "4DjE_VMjSSLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tu testuję różne rzeczy, ale tak, żeby się nie mieszały z resztą"
      ],
      "metadata": {
        "id": "syPpRv1ASUXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import getsizeof"
      ],
      "metadata": {
        "id": "cURdnLORTYq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "6YeG0gARSRea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"x.csv\"\n",
        "arr_pan = pd.read_csv(file_path, header=None, sep=\";\").astype(np.float16)\n",
        "arr_pol = pol.read_csv(file_path, has_header=False, separator=\";\").cast(pol.Float32)\n",
        "arr_num = arr_pan.to_numpy()\n",
        "print(arr_pol.dtypes)\n",
        "print(arr_num.dtype)\n",
        "arr_tor = torch.from_numpy(arr_num)\n",
        "print(arr_tor.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WW8QIpNySlri",
        "outputId": "6c568f7c-0858-405d-9412-2a92f89efe5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32]\n",
            "float16\n",
            "torch.float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:138: RuntimeWarning: overflow encountered in cast\n",
            "  return arr.astype(dtype, copy=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_pan.memory_usage()[0]*64+arr_pan.memory_usage()['Index'])\n",
        "print(arr_pol.estimated_size())\n",
        "print(arr_num.nbytes)\n",
        "print(arr_tor.storage().nbytes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prnP0gr7TcAE",
        "outputId": "1a4840ca-a037-4842-dc40-707b5eeaad99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n",
            "6144\n",
            "3072\n",
            "3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(arr_pan[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNyyMJ5MUKHq",
        "outputId": "e3bb58f4-2124-4cd6-f8ae-b5b4c4df2d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_pol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDW198yUNQL",
        "outputId": "6f275e31-f85f-4356-b72d-4aababcf4f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (120, 64)\n",
            "┌──────────┬──────────┬──────────┬──────────┬───┬───────────┬─────────────┬───────────┬───────────┐\n",
            "│ column_1 ┆ column_2 ┆ column_3 ┆ column_4 ┆ … ┆ column_61 ┆ column_62   ┆ column_63 ┆ column_64 │\n",
            "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---       ┆ ---         ┆ ---       ┆ ---       │\n",
            "│ i64      ┆ i64      ┆ i64      ┆ f64      ┆   ┆ str       ┆ f64         ┆ f64       ┆ f64       │\n",
            "╞══════════╪══════════╪══════════╪══════════╪═══╪═══════════╪═════════════╪═══════════╪═══════════╡\n",
            "│ 75       ┆ 1        ┆ 1        ┆ 982.0    ┆ … ┆ 75.0      ┆ 0.0         ┆ 75.0      ┆ 75.0      │\n",
            "│ 5310     ┆ 1        ┆ 2        ┆ 0.0      ┆ … ┆ 2655.0    ┆ 2261.327486 ┆ 4254.0    ┆ 1056.0    │\n",
            "│ 141      ┆ 0        ┆ 3        ┆ 0.0      ┆ … ┆ 70.5      ┆ 0.707107    ┆ 71.0      ┆ 70.0      │\n",
            "│ 151      ┆ 0        ┆ 2        ┆ 0.0      ┆ … ┆ 151.0     ┆ 0.0         ┆ 151.0     ┆ 151.0     │\n",
            "│ …        ┆ …        ┆ …        ┆ …        ┆ … ┆ …         ┆ …           ┆ …         ┆ …         │\n",
            "│ 252      ┆ 3        ┆ 1        ┆ 4290.0   ┆ … ┆ 84.0      ┆ 25.119713   ┆ 113.0     ┆ 69.0      │\n",
            "│ 74       ┆ 1        ┆ 1        ┆ 376.0    ┆ … ┆ 74.0      ┆ 0.0         ┆ 74.0      ┆ 74.0      │\n",
            "│ 123      ┆ 0        ┆ 2        ┆ 0.0      ┆ … ┆ 123.0     ┆ 0.0         ┆ 123.0     ┆ 123.0     │\n",
            "│ 199      ┆ 1        ┆ 1        ┆ 42.0     ┆ … ┆ 199.0     ┆ 0.0         ┆ 199.0     ┆ 199.0     │\n",
            "└──────────┴──────────┴──────────┴──────────┴───┴───────────┴─────────────┴───────────┴───────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmg9a2ijUNJC",
        "outputId": "53fe7b62-7560-444d-df0f-b4fb6226a2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[75 1 1 ... 0.0 75.0 75.0]\n",
            " [5310 1 2 ... 2261.327486234579 4254.0 1056.0]\n",
            " [141 0 3 ... 0.7071067811865476 71.0 70.0]\n",
            " ...\n",
            " [74 1 1 ... 0.0 74.0 74.0]\n",
            " [123 0 2 ... 0.0 123.0 123.0]\n",
            " [199 1 1 ... 0.0 199.0 199.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_tor)"
      ],
      "metadata": {
        "id": "Yhkv7tYDUNM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = torch.tensor([[1,2], [3,4]])\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4FsZsPNEO4",
        "outputId": "06b78489-9dce-4db3-9483-5114e6a67122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.reshape(s, (-1, 4))\n",
        "u = torch.reshape(s, (-1, 1))"
      ],
      "metadata": {
        "id": "rSwWbVxINPYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t)\n",
        "print(u)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX3pDS1gNZfD",
        "outputId": "14de9034-7392-4824-ef1e-a26f6b31cea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notatki, żeby nie szukać ciągle w artykule, bałagan trochę, ale są"
      ],
      "metadata": {
        "id": "pk2BaOAZkNbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "koszt - cross entropy\n",
        "\n",
        "aktywacja lineara - relu\n",
        "\n",
        "aktywacja po 16 neuronach - softmax\n",
        "\n",
        "zrobili L1, L2 i dropout, ale nie wchodziłam w to dokładnie\n",
        "\n",
        "batch - 64, 128 dawały najlepsze wyniki\n",
        "\n",
        "eksperymentalnie sprawdzili, że 100 epok daje zbieżność\n",
        "\n",
        "w adamie dali 0.0001 learning rate\n"
      ],
      "metadata": {
        "id": "5vWorsaTkQLk"
      }
    }
  ]
}