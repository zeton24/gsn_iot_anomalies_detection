{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WSU2a0sLxUeP",
        "xksGPv6tKcVf",
        "8XZXq2RN_8Fq",
        "lka_Av-N-0ZV",
        "VPwSvIEZ6dDF",
        "2ctLoR9A6iJg",
        "ogyerTgz_oHr",
        "yUGNwLMMytk3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d99dbeefc7842b9b39417e1dcdffb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f317bc726124bbfaff49a37e5de2e99",
              "IPY_MODEL_b204cdb6170244c29e68342f8959cd41",
              "IPY_MODEL_6a7b4d6f601d4fae9b54bbc59a2a9136"
            ],
            "layout": "IPY_MODEL_6e3acacbfb344ed0bd848d00380fc09b"
          }
        },
        "3f317bc726124bbfaff49a37e5de2e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc686754b21949d6ad876c09d0d37844",
            "placeholder": "​",
            "style": "IPY_MODEL_2f944daa18694024b5631e7b21395ad1",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "b204cdb6170244c29e68342f8959cd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b3bf35525c44bcfb700daca602a4ea6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c8f6f01eec94dbcad4340737a7c6637",
            "value": 2
          }
        },
        "6a7b4d6f601d4fae9b54bbc59a2a9136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_016a11b338a64661a87939596a200a00",
            "placeholder": "​",
            "style": "IPY_MODEL_a6105169216e48f493d78439ffe4e55e",
            "value": " 2/2 [00:00&lt;00:00,  4.68it/s]"
          }
        },
        "6e3acacbfb344ed0bd848d00380fc09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "fc686754b21949d6ad876c09d0d37844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f944daa18694024b5631e7b21395ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b3bf35525c44bcfb700daca602a4ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8f6f01eec94dbcad4340737a7c6637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "016a11b338a64661a87939596a200a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6105169216e48f493d78439ffe4e55e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9675a44060d548f098a043367dade021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37e299b4a2a84bfa945b3b9c45715baf",
              "IPY_MODEL_138256a239984700b86d95276bbd8660",
              "IPY_MODEL_f950643bf8f7414bbe095dae54a9e5de"
            ],
            "layout": "IPY_MODEL_6254907eba2d4e1d9d8840bd6b48a9a4"
          }
        },
        "37e299b4a2a84bfa945b3b9c45715baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb6d656182643d2bbf6ec0bde59cb2f",
            "placeholder": "​",
            "style": "IPY_MODEL_2ddc38eae5fc44dfbc1cfe35a02f5b78",
            "value": "Epoch 0:   1%"
          }
        },
        "138256a239984700b86d95276bbd8660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6adcabe7aa44013801d8a3092c42ef5",
            "max": 6601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffbe09d130d24bc2b06034115104f182",
            "value": 91
          }
        },
        "f950643bf8f7414bbe095dae54a9e5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68f96d10234747de82cf0026434dc996",
            "placeholder": "​",
            "style": "IPY_MODEL_5328998ea118465b969a61ff1b41f8c9",
            "value": " 91/6601 [01:07&lt;1:20:14,  1.35it/s, v_num=4]"
          }
        },
        "6254907eba2d4e1d9d8840bd6b48a9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6eb6d656182643d2bbf6ec0bde59cb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ddc38eae5fc44dfbc1cfe35a02f5b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6adcabe7aa44013801d8a3092c42ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbe09d130d24bc2b06034115104f182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68f96d10234747de82cf0026434dc996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5328998ea118465b969a61ff1b41f8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional (Conv2d)\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
        "\n",
        "Average Pooling https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d\n",
        "\n",
        "Normalization\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d\n",
        "\n",
        "Spatial Dropout\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html#torch.nn.Dropout2d\n",
        "\n",
        "Fully connected layer -> nn.Linear()\n"
      ],
      "metadata": {
        "id": "f8AlM5uOovz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stara wersja"
      ],
      "metadata": {
        "id": "WSU2a0sLxUeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "YsotMKY_-viE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "cM7kc7THAPKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset i Dataloader"
      ],
      "metadata": {
        "id": "xksGPv6tKcVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "todo\n",
        " - transformy w datasecie\n",
        " - tensory na wyjściu dataloadera"
      ],
      "metadata": {
        "id": "GmT59WpvYdG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(category, n_classes):\n",
        "  result = torch.zeros(n_classes)\n",
        "  result[category] = 1\n",
        "  return result"
      ],
      "metadata": {
        "id": "YcYWDfJyAL0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wzięte z https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "# i znacząco zmienione, bo my mamy 1 plik wejściowy, a oni folder z obrazkami\n",
        "# jak to nie będzie mega powolne, to spoko, ale może być powolne i wtedy nie wiem, co robimy\n",
        "\n",
        "class IoTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, input_file):\n",
        "    self.input_file = open(input_file, \"r\")\n",
        "    self.dict_of_classes = {\"Mirai-Ackflooding\": 0, \"Mirai-Hostbruteforceg\": 1, \"Mirai-UDP Flooding\": 2, \"Mirai-HTTP Flooding\": 3,\n",
        "                            \"DoS-Synflooding\": 4, \"Scan Port OS\": 5, \"Normal\": 6} # todo reszta klas\n",
        "    self.n_classes = 16 # len(self.dict_of_classes)\n",
        "\n",
        "  def __len__(self):\n",
        "    i = 0\n",
        "    for i, line in enumerate(self.input_file):\n",
        "      pass\n",
        "    self.input_file.seek(0)\n",
        "    return 4 # i + 1\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    for i, line in enumerate(self.input_file):\n",
        "      if i == idx:\n",
        "        data = line.split(\";\") # docelowo zmienić na \",\"\n",
        "\n",
        "        image = torch.Tensor(list(map(float, data[:64])))\n",
        "        image = torch.reshape(image, (1,64))\n",
        "\n",
        "        label = data[-1]\n",
        "        if label.endswith(\"\\n\"):\n",
        "          label = label[:-1]\n",
        "        label = self.dict_of_classes[label] # -2, lub -3 dla prostszych przypadków\n",
        "        label = to_one_hot(label, self.n_classes)\n",
        "\n",
        "        self.input_file.seek(0)\n",
        "        break\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "jwh6V7mTKbTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = IoTDataset(\"test_dataset.csv\")\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "R1MIiyx0QK9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_features, train_labels in dataloader:\n",
        "  print(train_features.shape, train_features.dtype)\n",
        "  print(train_labels)\n",
        "  break"
      ],
      "metadata": {
        "id": "MfobgY3tXgeE",
        "outputId": "9d22aff0-333d-4b69-a2d1-101a7a4bc3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 64]) torch.float32\n",
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elementy do wykorzystania"
      ],
      "metadata": {
        "id": "8XZXq2RN_8Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modele sieci 1D, 2D, 3D"
      ],
      "metadata": {
        "id": "lka_Av-N-0ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model1D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        # Nazwa bloku do rozważenia, taka mi się wymyśliła, ale nie upieram się przy niej.\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 16)\n",
        "            # Bez aktywacji na końcu, bo softmax się doda automatycznie razem z cross entropy.\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DMoPFNCg-5Tr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f1b21e0e-be2f-4209-8ba9-70dd3b22255a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4ce83ec1fd62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModel1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         self.convblock1 = nn.Sequential(\n\u001b[1;32m      5\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Oni w artykule dają normalizację, ale pytorch wywala błąd.\n",
        "            # Moim zdaniem słusznie, bo o ile rozumiem ten wzór na normalizację (co jest w dokumentacji),\n",
        "            # to przy wymiarze wejścia [batch_size, 256, 1, 1] wyjście to tensor zer o takim samym wymiarze.\n",
        "            # Po prostu normalizacja zmienia nam średnią na 0 (odchylenie standardowe też, ale to nieistotne),\n",
        "            # a jak mamy 1 element, to zmiana średniej na 0, to zmiana elementu na 0.\n",
        "            # Więc nawet jak jakoś obejdziemy ten błąd, to wyniki będą bez sensu.\n",
        "            # Moim zdaniem w artykule jest błąd (a przynajmniej na rysunku, może w implementacji tego nie ma).\n",
        "\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 16)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (x.shape[0],1,8,8)) # można ten reshape dać gdzie indziej jak się znajdzie lepsze miejsce\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BI-iPxXK-5M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwt-wXMAd5-L"
      },
      "outputs": [],
      "source": [
        "class Model3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.AvgPool3d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.AvgPool3d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm3d(256),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 16)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (x.shape[0],1,4,4,4))\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch loader"
      ],
      "metadata": {
        "id": "VPwSvIEZ6dDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Na bazie datasetu z labów - zwraca kolejne batche.\n",
        "# Nie jest jakiś genialny, ale i tak go używam tylko tu do testów.\n",
        "\n",
        "class Dataset:\n",
        "  def __init__(self, data, labels, batch_size=1):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.n_batches = len(self.data) // batch_size\n",
        "\n",
        "  def __iter__(self):\n",
        "    for i in range(self.n_batches):\n",
        "      inputs = torch.zeros(self.batch_size, 1, 64) # shape zahardkodowany\n",
        "      labels = torch.zeros(self.batch_size, self.labels.shape[1])\n",
        "\n",
        "      for j in range(self.batch_size):\n",
        "        inputs[j, 0] = self.data[i*self.batch_size+j]\n",
        "        labels[j]= self.labels[i*self.batch_size+j]\n",
        "\n",
        "      yield inputs, labels\n",
        "\n",
        "  # todo - jakiś shuffle by się przydał, ale to tylko jeśli byśmy z tego korzystały"
      ],
      "metadata": {
        "id": "aSnHM9rz2uYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funkcje do treningu i testowania"
      ],
      "metadata": {
        "id": "2ctLoR9A6iJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja przeprowadzająca traning\n",
        "def train(net, loader, optimizer, criterion, epochs):\n",
        "  net.train()\n",
        "  for epoch in range(epochs):\n",
        "    epoch_loss = 0.\n",
        "    for i, (inputs, labels) in enumerate(loader):\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss\n",
        "\n",
        "    # Wczesne przerwanie w razie dostatecznie dobrych wyników.\n",
        "    if epoch_loss<0.05:\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] eloss: {epoch_loss:.3f}')\n",
        "      break\n",
        "\n",
        "    if epoch % 20 == 19: # wypisywanie co 20 epok\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] eloss: {epoch_loss:.3f}')"
      ],
      "metadata": {
        "id": "80aVYkDFK4oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(network, test_set, n_classes = 16):\n",
        "  network.eval() # Przełącza sieć w tryb testowania, m. in. wyłącza dropouta.\n",
        "  err_matrix = torch.zeros((n_classes, n_classes), dtype=int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for inputs, labels in test_set:\n",
        "\n",
        "      outputs = network(inputs)\n",
        "\n",
        "      _, label = torch.max(labels, 1)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "      for truth, prediction in zip(label, predicted):\n",
        "        err_matrix[truth, prediction] += 1\n",
        "\n",
        "  return err_matrix"
      ],
      "metadata": {
        "id": "HKHJHsinOxPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja tworzy losowe etykiety one-hot.\n",
        "\n",
        "def rand_and_predict(dataset_size, output_length):\n",
        "  labels = torch.zeros(dataset_size, output_length)\n",
        "  for i in range(dataset_size):\n",
        "    hot = torch.randint(output_length,(1,))\n",
        "    labels[i, hot] = 1\n",
        "  return labels\n"
      ],
      "metadata": {
        "id": "vp9UCrvpG6LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test na małych danych"
      ],
      "metadata": {
        "id": "ogyerTgz_oHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputsR = torch.rand(24,1,64)\n",
        "labelsR = rand_and_predict(24,16)"
      ],
      "metadata": {
        "id": "gs1Ignft8Yru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {\"Mirai-Ackflooding\": 0, \"Mirai-Hostbruteforceg\": 1, \"Mirai-UDP Flooding\": 2, \"Mirai-HTTP Flooding\": 3, \"DoS-Synflooding\": 4, \"Scan Port OS\": 5, \"Normal\": 6}\n",
        "inputs = torch.zeros(24,1,64)\n",
        "labels = torch.zeros(24,16)\n",
        "with open('test_dataset.csv') as f:\n",
        "  for i, line in enumerate(f):\n",
        "    data = line.split(\";\") # docelowo zmienić na \",\"\n",
        "    image = torch.Tensor(list(map(float, data[1:65])))\n",
        "    image = torch.reshape(image, (1,64))\n",
        "\n",
        "    label = data[-1]\n",
        "    if label.endswith(\"\\n\"):\n",
        "      label = label[:-1]\n",
        "    label = classes[label]\n",
        "    label = to_one_hot(label, 16)\n",
        "\n",
        "    inputs[i] = image\n",
        "    labels[i] = label"
      ],
      "metadata": {
        "id": "kvYZRLjhGL-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = Dataset(inputs, labels, batch_size=1)"
      ],
      "metadata": {
        "id": "IIyXs5qFrd8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_test = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "dcips5nY1GwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1D"
      ],
      "metadata": {
        "id": "skdjpL2v8Tue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network1 = Model1D()\n",
        "optimizer1 = optim.Adam(network1.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "aM2wHDnc86Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(network1, dataloader, optimizer1, criterion, 1000)"
      ],
      "metadata": {
        "id": "8zkn_Dco9CGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d042ef-0c4f-4145-d75b-1abc0649bfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20,     2] eloss: 0.773\n",
            "[40,     2] eloss: 0.464\n",
            "[60,     2] eloss: 0.220\n",
            "[65,     2] eloss: 0.046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = test(network1, dataloader)\n",
        "print(f\"Accuracy: {sum(sum(result1*torch.eye(16)))*100/sum(sum(result1)):.2f}%\")\n",
        "print(result1)"
      ],
      "metadata": {
        "id": "XgWnwhTb5McQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9945b0f-d5bc-4bb5-9f7a-01fe8331c29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2D"
      ],
      "metadata": {
        "id": "S8AgdBFHBHbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network2 = Model2D()\n",
        "optimizer2 = optim.Adam(network2.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "DLvlw3ilBHbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(network2, dataloader, optimizer2, criterion, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ed12fb-a7ca-4875-b36d-1b592f140b99",
        "id": "WI6na7CEBHbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20,     2] eloss: 3.156\n",
            "[40,     2] eloss: 3.729\n",
            "[60,     2] eloss: 2.365\n",
            "[80,     2] eloss: 1.382\n",
            "[100,     2] eloss: 0.487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = test(network2, dataloader)\n",
        "print(f\"Accuracy: {sum(sum(result2*torch.eye(16)))*100/sum(sum(result2)):.2f}%\")\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620de886-a9ae-4348-d33e-a2b9b6404331",
        "id": "xDRV00hzBHbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.00%\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3D"
      ],
      "metadata": {
        "id": "Z_P-0rNkFxnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network3 = Model3D()\n",
        "optimizer3 = optim.Adam(network3.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7-Mk5B2KFxnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(network3, dataloader, optimizer3, criterion, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92415661-accd-42cc-aa83-dbfc0399dbb8",
        "id": "3I0UN6PhFxnE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20,     2] eloss: 1.973\n",
            "[40,     2] eloss: 1.932\n",
            "[60,     2] eloss: 2.405\n",
            "[80,     2] eloss: 3.536\n",
            "[100,     2] eloss: 2.386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result3 = test(network3, dataloader)\n",
        "print(f\"Accuracy: {sum(sum(result3*torch.eye(16)))*100/sum(sum(result3)):.2f}%\")\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ad2c0c-bb1d-44ed-c0ed-ea0a311379c2",
        "id": "9oslUrSAFxnE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.00%\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lightning"
      ],
      "metadata": {
        "id": "l4pUUVvFxbN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vWsChpYB0KWJ",
        "outputId": "68e6d4e8-ff42-471b-dc3e-024cf86553c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Collecting polars\n",
            "  Downloading polars-0.20.26-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "  Attempting uninstall: polars\n",
            "    Found existing installation: polars 0.20.2\n",
            "    Uninstalling polars-0.20.2:\n",
            "      Successfully uninstalled polars-0.20.2\n",
            "Successfully installed polars-0.20.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch-lightning"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Uv1-bhe_PWNI",
        "outputId": "bef77dfc-99b3-45c0-b02f-91986b35a094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.4 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import polars\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "from torchmetrics import Accuracy\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "kTh52XTTypc2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import PIL\n",
        "#import torchmetrics\n",
        "#from IPython.display import display\n",
        "#from pytorch_lightning import Trainer\n",
        "#from scipy.io import loadmat\n",
        "\n",
        "#from torchvision import models\n",
        "#from torchvision.datasets import ImageFolder\n",
        "#from torchvision.transforms import Resize, Compose, ToTensor, Normalize, ToPILImage\n",
        "#import hydra\n",
        "#from hydra.utils import instantiate\n",
        "\n",
        "#import torchvision\n",
        "#from torchmetrics.classification import accuracy\n"
      ],
      "metadata": {
        "id": "VLRNKnYlPVzP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dane"
      ],
      "metadata": {
        "id": "0LsCRRZTy15-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LazyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, inputs: torch.tensor, labels: torch.tensor, n_classes: int):\n",
        "    self.inputs = inputs\n",
        "    self.labels = labels\n",
        "    self.n_classes = n_classes\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    temp = torch.zeros(self.n_classes)\n",
        "    temp[self.labels[idx].item()] = 1\n",
        "    return self.inputs[idx], temp"
      ],
      "metadata": {
        "id": "NDCFHXBeZeK1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IoTDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, file_id: str, file_name: str, batch_size: int=64, binary_classification: bool=False):\n",
        "    super().__init__()\n",
        "    self.file_id = file_id\n",
        "    self.file_name = file_name\n",
        "    self.batch_size = batch_size\n",
        "    self.binary_classification = binary_classification\n",
        "\n",
        "    if self.binary_classification:\n",
        "      self.n_classes = 2\n",
        "      self.mapping = {\"Normal\": 0, \"Anomaly\": 1}\n",
        "    else:\n",
        "      self.n_classes = 5\n",
        "      self.mapping = {'Normal': 0, 'Mirai': 1, 'DoS': 2, 'Scan': 3, 'MITM ARP Spoofing': 4}\n",
        "\n",
        "  def prepare_data(self):\n",
        "    if not os.path.exists(self.file_name):\n",
        "      gdown.download(id=self.file_id, output=self.file_name)\n",
        "\n",
        "  def setup(self,stage = None):\n",
        "    data = torch.reshape(polars.read_csv(self.file_name, columns = range(64)).cast(polars.Float32).to_torch().to(torch.half), (-1, 1, 64))\n",
        "\n",
        "    if self.binary_classification:\n",
        "      labels = torch.reshape(polars.read_csv(self.file_name, columns = [64])['Label'].replace(self.mapping, return_dtype=polars.UInt8).to_torch(), (-1, 1))\n",
        "    else:\n",
        "      #labels = torch.reshape(polars.read_csv(self.file_name, columns = [65])['Cat'].replace(self.mapping, return_dtype=polars.UInt8).to_torch(), (-1, 1))\n",
        "      labels = polars.read_csv(self.file_name, columns = [65])['Cat'].replace(self.mapping, return_dtype=polars.UInt8).to_torch()\n",
        "    dataset = LazyDataset(data, labels, self.n_classes)\n",
        "    del data, labels\n",
        "\n",
        "    # Train, test i val.\n",
        "    l = len(dataset)\n",
        "    train_and_val_size = int(l * .75)\n",
        "    dataset, self.test_dataset = random_split(dataset, [train_and_val_size, l - train_and_val_size])\n",
        "\n",
        "    train_size = int(train_and_val_size * .9)\n",
        "    self.train_dataset, self.val_dataset = random_split(dataset, [train_size, train_and_val_size - train_size])\n",
        "    del dataset\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ],
      "metadata": {
        "id": "0h7Dt7zeNvHw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = IoTDataModule(file_id='1k8RqOM7hBvL8uomcKnnLr5HasYRWnYeW', file_name='iot-intrusion_with_headers.csv')"
      ],
      "metadata": {
        "id": "PVkbHeqvmnTc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.prepare_data()\n",
        "dm.setup()"
      ],
      "metadata": {
        "id": "tUGwTG_FsB4L"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = len(dm.train_dataset)\n",
        "b = len(dm.val_dataset)\n",
        "c = len(dm.test_dataset)\n",
        "d=a+b+c"
      ],
      "metadata": {
        "id": "EZROdc9jyMwB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(d)\n",
        "print(a/d*40/27)\n",
        "print(b/d*40/3)\n",
        "print(c/d*4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq0iKMofcBa7",
        "outputId": "8b96a41a-4d11-4982-f351-629617e8e886"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625783\n",
            "0.9999987571126449\n",
            "1.000005859326103\n",
            "1.0000015979980281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input, label in dm.test_dataloader():\n",
        "  print(input.shape)\n",
        "  print(label.T)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KesQhlhPc5as",
        "outputId": "fdbb0da2-5e45-47a1-97c3-993648e77b42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 64])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
            "        [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "         0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
            "         1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "yUGNwLMMytk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model1D(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, padding='same'),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.AvgPool1d(2),\n",
        "            nn.Dropout(p=0.05)\n",
        "        )\n",
        "\n",
        "        # Nazwa bloku do rozważenia, taka mi się wymyśliła, ale nie upieram się przy niej.\n",
        "        self.evaluator = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, num_classes)\n",
        "            # Bez aktywacji na końcu, bo softmax się doda automatycznie razem z cross entropy.\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.evaluator(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mWHQzJuN3fmQ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnomalyClassifier(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, lr, model_type=1, binary_classification=False):\n",
        "    super().__init__()\n",
        "    self.lr = lr\n",
        "    self.current_epoch_training_loss = torch.tensor(0.0)\n",
        "    self.training_step_outputs = []\n",
        "    self.validation_step_outputs = []\n",
        "\n",
        "    self.num_classes = 2 if binary_classification else 5\n",
        "    self.accuracy = Accuracy(task='multiclass', num_classes=self.num_classes) # I sposób na metryke\n",
        "\n",
        "    if model_type == 1:\n",
        "      self.model = Model1D(self.num_classes)\n",
        "    elif model_type == 2:\n",
        "      self.model = Model2D(self.num_classes)\n",
        "    else:\n",
        "      self.model = Model3D(self.num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "  def compute_loss(self, x, y):\n",
        "    return F.cross_entropy(x, y)\n",
        "\n",
        "  def common_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    outputs = self(x)\n",
        "    loss = self.compute_loss(outputs,y)\n",
        "    return loss, outputs, y\n",
        "\n",
        "  def common_test_valid_step(self, batch, batch_idx):\n",
        "    loss, outputs, y = self.common_step(batch, batch_idx)\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "    acc = self.accuracy(outputs, y)\n",
        "    return loss, acc\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss, outputs, y = self.common_step(batch, batch_idx)\n",
        "    self.training_step_outputs.append(loss)\n",
        "    accuracy = self.accuracy(outputs, y)\n",
        "\n",
        "    self.log_dict({\"train_loss\": loss, \"train_accuracy\": accuracy}, on_step = False, on_epoch = True, prog_bar = True) # logger=True?\n",
        "    return {'loss':loss}\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "    outs = torch.stack(self.training_step_outputs)\n",
        "    self.current_epoch_training_loss = outs.mean()\n",
        "    self.training_step_outputs.clear()\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss, acc = self.common_test_valid_step(batch, batch_idx)\n",
        "    self.validation_step_outputs.append(loss)\n",
        "\n",
        "    self.log_dict({'val_loss': loss, 'val_acc': acc}, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    return {'val_loss':loss, 'val_acc': acc}\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "    outs = torch.stack(self.validation_step_outputs)\n",
        "    avg_loss = outs.mean()\n",
        "    self.logger.experiment.add_scalars('train and vall losses', {'train': self.current_epoch_training_loss.item() , 'val': avg_loss.item()}, self.current_epoch)\n",
        "    self.validation_step_outputs.clear()\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    loss, acc = self.common_test_valid_step(batch, batch_idx)\n",
        "\n",
        "    self.log_dict({'test_loss': loss, 'test_acc': acc}, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    return {'test_loss': loss, 'test_acc': acc}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer =  torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "    return [optimizer], [lr_scheduler]"
      ],
      "metadata": {
        "id": "YhvuqsjAxmL3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### trening"
      ],
      "metadata": {
        "id": "gtPyceigyxaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = AnomalyClassifier(0.001, model_type=1)"
      ],
      "metadata": {
        "id": "s_rWKbCp3HLK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(accelerator=\"auto\", max_epochs=1, precision=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExzxhZUg3J8g",
        "outputId": "16c49660-fb5a-4d93-c9f4-36ab04e6788d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:556: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(classifier, dm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "2d99dbeefc7842b9b39417e1dcdffb30",
            "3f317bc726124bbfaff49a37e5de2e99",
            "b204cdb6170244c29e68342f8959cd41",
            "6a7b4d6f601d4fae9b54bbc59a2a9136",
            "6e3acacbfb344ed0bd848d00380fc09b",
            "fc686754b21949d6ad876c09d0d37844",
            "2f944daa18694024b5631e7b21395ad1",
            "6b3bf35525c44bcfb700daca602a4ea6",
            "7c8f6f01eec94dbcad4340737a7c6637",
            "016a11b338a64661a87939596a200a00",
            "a6105169216e48f493d78439ffe4e55e",
            "9675a44060d548f098a043367dade021",
            "37e299b4a2a84bfa945b3b9c45715baf",
            "138256a239984700b86d95276bbd8660",
            "f950643bf8f7414bbe095dae54a9e5de",
            "6254907eba2d4e1d9d8840bd6b48a9a4",
            "6eb6d656182643d2bbf6ec0bde59cb2f",
            "2ddc38eae5fc44dfbc1cfe35a02f5b78",
            "a6adcabe7aa44013801d8a3092c42ef5",
            "ffbe09d130d24bc2b06034115104f182",
            "68f96d10234747de82cf0026434dc996",
            "5328998ea118465b969a61ff1b41f8c9"
          ]
        },
        "id": "jmMMpoym3O7k",
        "outputId": "17588b8e-7939-4a22-cd8d-6f938242ed5b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name     | Type               | Params\n",
            "------------------------------------------------\n",
            "0 | accuracy | MulticlassAccuracy | 0     \n",
            "1 | model    | Model1D            | 744 K \n",
            "------------------------------------------------\n",
            "744 K     Trainable params\n",
            "0         Non-trainable params\n",
            "744 K     Total params\n",
            "2.976     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d99dbeefc7842b9b39417e1dcdffb30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9675a44060d548f098a043367dade021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poligon"
      ],
      "metadata": {
        "id": "4DjE_VMjSSLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tu testuję różne rzeczy, ale tak, żeby się nie mieszały z resztą"
      ],
      "metadata": {
        "id": "syPpRv1ASUXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import getsizeof"
      ],
      "metadata": {
        "id": "cURdnLORTYq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "6YeG0gARSRea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"x.csv\"\n",
        "arr_pan = pd.read_csv(file_path, header=None, sep=\";\").astype(np.float16)\n",
        "arr_pol = pol.read_csv(file_path, has_header=False, separator=\";\").cast(pol.Float32)\n",
        "arr_num = arr_pan.to_numpy()\n",
        "print(arr_pol.dtypes)\n",
        "print(arr_num.dtype)\n",
        "arr_tor = torch.from_numpy(arr_num)\n",
        "print(arr_tor.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WW8QIpNySlri",
        "outputId": "6c568f7c-0858-405d-9412-2a92f89efe5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32, Float32]\n",
            "float16\n",
            "torch.float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:138: RuntimeWarning: overflow encountered in cast\n",
            "  return arr.astype(dtype, copy=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_pan.memory_usage()[0]*64+arr_pan.memory_usage()['Index'])\n",
        "print(arr_pol.estimated_size())\n",
        "print(arr_num.nbytes)\n",
        "print(arr_tor.storage().nbytes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prnP0gr7TcAE",
        "outputId": "1a4840ca-a037-4842-dc40-707b5eeaad99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n",
            "6144\n",
            "3072\n",
            "3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(arr_pan[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNyyMJ5MUKHq",
        "outputId": "e3bb58f4-2124-4cd6-f8ae-b5b4c4df2d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_pol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDW198yUNQL",
        "outputId": "6f275e31-f85f-4356-b72d-4aababcf4f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (120, 64)\n",
            "┌──────────┬──────────┬──────────┬──────────┬───┬───────────┬─────────────┬───────────┬───────────┐\n",
            "│ column_1 ┆ column_2 ┆ column_3 ┆ column_4 ┆ … ┆ column_61 ┆ column_62   ┆ column_63 ┆ column_64 │\n",
            "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---       ┆ ---         ┆ ---       ┆ ---       │\n",
            "│ i64      ┆ i64      ┆ i64      ┆ f64      ┆   ┆ str       ┆ f64         ┆ f64       ┆ f64       │\n",
            "╞══════════╪══════════╪══════════╪══════════╪═══╪═══════════╪═════════════╪═══════════╪═══════════╡\n",
            "│ 75       ┆ 1        ┆ 1        ┆ 982.0    ┆ … ┆ 75.0      ┆ 0.0         ┆ 75.0      ┆ 75.0      │\n",
            "│ 5310     ┆ 1        ┆ 2        ┆ 0.0      ┆ … ┆ 2655.0    ┆ 2261.327486 ┆ 4254.0    ┆ 1056.0    │\n",
            "│ 141      ┆ 0        ┆ 3        ┆ 0.0      ┆ … ┆ 70.5      ┆ 0.707107    ┆ 71.0      ┆ 70.0      │\n",
            "│ 151      ┆ 0        ┆ 2        ┆ 0.0      ┆ … ┆ 151.0     ┆ 0.0         ┆ 151.0     ┆ 151.0     │\n",
            "│ …        ┆ …        ┆ …        ┆ …        ┆ … ┆ …         ┆ …           ┆ …         ┆ …         │\n",
            "│ 252      ┆ 3        ┆ 1        ┆ 4290.0   ┆ … ┆ 84.0      ┆ 25.119713   ┆ 113.0     ┆ 69.0      │\n",
            "│ 74       ┆ 1        ┆ 1        ┆ 376.0    ┆ … ┆ 74.0      ┆ 0.0         ┆ 74.0      ┆ 74.0      │\n",
            "│ 123      ┆ 0        ┆ 2        ┆ 0.0      ┆ … ┆ 123.0     ┆ 0.0         ┆ 123.0     ┆ 123.0     │\n",
            "│ 199      ┆ 1        ┆ 1        ┆ 42.0     ┆ … ┆ 199.0     ┆ 0.0         ┆ 199.0     ┆ 199.0     │\n",
            "└──────────┴──────────┴──────────┴──────────┴───┴───────────┴─────────────┴───────────┴───────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmg9a2ijUNJC",
        "outputId": "53fe7b62-7560-444d-df0f-b4fb6226a2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[75 1 1 ... 0.0 75.0 75.0]\n",
            " [5310 1 2 ... 2261.327486234579 4254.0 1056.0]\n",
            " [141 0 3 ... 0.7071067811865476 71.0 70.0]\n",
            " ...\n",
            " [74 1 1 ... 0.0 74.0 74.0]\n",
            " [123 0 2 ... 0.0 123.0 123.0]\n",
            " [199 1 1 ... 0.0 199.0 199.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr_tor)"
      ],
      "metadata": {
        "id": "Yhkv7tYDUNM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = torch.tensor([[1,2], [3,4]])\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh4FsZsPNEO4",
        "outputId": "06b78489-9dce-4db3-9483-5114e6a67122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.reshape(s, (-1, 4))\n",
        "u = torch.reshape(s, (-1, 1))"
      ],
      "metadata": {
        "id": "rSwWbVxINPYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t)\n",
        "print(u)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX3pDS1gNZfD",
        "outputId": "14de9034-7392-4824-ef1e-a26f6b31cea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notatki, żeby nie szukać ciągle w artykule, bałagan trochę, ale są"
      ],
      "metadata": {
        "id": "pk2BaOAZkNbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "koszt - cross entropy\n",
        "\n",
        "aktywacja lineara - relu\n",
        "\n",
        "aktywacja po 16 neuronach - softmax\n",
        "\n",
        "zrobili L1, L2 i dropout, ale nie wchodziłam w to dokładnie\n",
        "\n",
        "batch - 64, 128 dawały najlepsze wyniki\n",
        "\n",
        "eksperymentalnie sprawdzili, że 100 epok daje zbieżność\n",
        "\n",
        "w adamie dali 0.0001 learning rate\n"
      ],
      "metadata": {
        "id": "5vWorsaTkQLk"
      }
    }
  ]
}